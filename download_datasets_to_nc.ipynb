{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045f153e-7743-42ed-a4c0-8fe05e5e697b",
   "metadata": {},
   "source": [
    "This notebook filters and selects the required CMIP6 datasets based on specified models, variables, scenarios, and locations. It then downloads the relevant data and saves it locally in .nc (NetCDF) format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1560d11f-1c4c-4327-a573-dc474cd2b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 23:07:06,518 - INFO - Downloading CMIP6 catalog...\n",
      "2025-04-09 23:08:07,234 - INFO - Downloading historical tas data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:07,234 - INFO - Downloading historical pr data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:07,235 - INFO - Downloading ssp245 tas data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:07,236 - INFO - Downloading ssp245 pr data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:19,201 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out\n",
      "2025-04-09 23:08:23,163 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: timed out\n",
      "2025-04-09 23:08:28,186 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: timed out\n",
      "2025-04-09 23:08:28,187 - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
      "2025-04-09 23:08:28,192 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x72e78749c7a0>: Failed to resolve 'metadata.google.internal' ([Errno -2] Name or service not known)\"))\n",
      "2025-04-09 23:08:29,263 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x72e787095550>: Failed to resolve 'metadata.google.internal' ([Errno -2] Name or service not known)\"))\n",
      "2025-04-09 23:08:31,429 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x72e787095910>: Failed to resolve 'metadata.google.internal' ([Errno -2] Name or service not known)\"))\n",
      "2025-04-09 23:08:35,605 - WARNING - Compute Engine Metadata server unavailable on attempt 4 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x72e787095220>: Failed to resolve 'metadata.google.internal' ([Errno -2] Name or service not known)\"))\n",
      "2025-04-09 23:08:44,152 - WARNING - Compute Engine Metadata server unavailable on attempt 5 of 5. Reason: HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/service-accounts/default/?recursive=true (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x72e787095e20>: Failed to resolve 'metadata.google.internal' ([Errno -2] Name or service not known)\"))\n",
      "HDF5-DIAG: Error detected in HDF5 (1.14.3) thread 1:\n",
      "  #000: H5Adeprec.c line 140 in H5Acreate1(): unable to create attribute\n",
      "    major: Attribute\n",
      "    minor: Unable to initialize object\n",
      "  #001: H5VLcallback.c line 1034 in H5VL_attr_create(): attribute create failed\n",
      "    major: Virtual Object Layer\n",
      "    minor: Unable to create file\n",
      "  #002: H5VLcallback.c line 1001 in H5VL__attr_create(): attribute create failed\n",
      "    major: Virtual Object Layer\n",
      "    minor: Unable to create file\n",
      "  #003: H5VLnative_attr.c line 110 in H5VL__native_attr_create(): unable to create attribute\n",
      "    major: Attribute\n",
      "    minor: Unable to initialize object\n",
      "  #004: H5Aint.c line 265 in H5A__create(): attribute already exists\n",
      "    major: Attribute\n",
      "    minor: Object already exists\n",
      "HDF5-DIAG: Error detected in HDF5 (1.14.3) thread 1:\n",
      "  #000: H5Adeprec.c line 140 in H5Acreate1(): unable to create attribute\n",
      "    major: Attribute\n",
      "    minor: Unable to initialize object\n",
      "  #001: H5VLcallback.c line 1034 in H5VL_attr_create(): attribute create failed\n",
      "    major: Virtual Object Layer\n",
      "    minor: Unable to create file\n",
      "  #002: H5VLcallback.c line 1001 in H5VL__attr_create(): attribute create failed\n",
      "    major: Virtual Object Layer\n",
      "    minor: Unable to create file\n",
      "  #003: H5VLnative_attr.c line 110 in H5VL__native_attr_create(): unable to create attribute\n",
      "    major: Attribute\n",
      "    minor: Unable to initialize object\n",
      "  #004: H5Aint.c line 265 in H5A__create(): attribute already exists\n",
      "    major: Attribute\n",
      "    minor: Object already exists\n",
      "2025-04-09 23:08:48,221 - ERROR - Error downloading {'source': 'UKESM1-0-LL', 'experiment': 'historical', 'variable': 'pr', 'member': 'r1i1p1f2', 'table': 'Amon'}: NetCDF: Can't open HDF5 attribute\n",
      "2025-04-09 23:08:48,222 - INFO - Downloading ssp585 tas data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:48,226 - ERROR - Error downloading {'source': 'UKESM1-0-LL', 'experiment': 'ssp245', 'variable': 'pr', 'member': 'r1i1p1f2', 'table': 'Amon'}: NetCDF: String match to name in use\n",
      "2025-04-09 23:08:48,227 - INFO - Downloading ssp585 pr data for UKESM1-0-LL...\n",
      "2025-04-09 23:08:48,767 - ERROR - Error downloading {'source': 'UKESM1-0-LL', 'experiment': 'ssp245', 'variable': 'tas', 'member': 'r1i1p1f2', 'table': 'Amon'}: NetCDF: String match to name in use\n",
      "2025-04-09 23:08:48,769 - INFO - Downloading historical tas data for CESM2-WACCM...\n",
      "2025-04-09 23:08:48,773 - ERROR - Error downloading {'source': 'UKESM1-0-LL', 'experiment': 'historical', 'variable': 'tas', 'member': 'r1i1p1f2', 'table': 'Amon'}: NetCDF: Not a valid ID\n",
      "2025-04-09 23:08:48,774 - INFO - Downloading historical pr data for CESM2-WACCM...\n",
      "2025-04-09 23:08:52,744 - INFO - Saved dataset to datasets/cmip6_pr_ssp585_UKESM1-0-LL.nc\n",
      "2025-04-09 23:08:52,746 - INFO - Downloading ssp245 tas data for CESM2-WACCM...\n",
      "2025-04-09 23:08:53,467 - INFO - Saved dataset to datasets/cmip6_tas_ssp585_UKESM1-0-LL.nc\n",
      "2025-04-09 23:08:53,468 - INFO - Downloading ssp245 pr data for CESM2-WACCM...\n",
      "2025-04-09 23:08:54,217 - INFO - Saved dataset to datasets/cmip6_tas_historical_CESM2-WACCM.nc\n",
      "2025-04-09 23:08:54,219 - INFO - Downloading ssp585 tas data for CESM2-WACCM...\n",
      "2025-04-09 23:08:56,529 - INFO - Saved dataset to datasets/cmip6_pr_historical_CESM2-WACCM.nc\n",
      "2025-04-09 23:08:56,530 - INFO - Downloading ssp585 pr data for CESM2-WACCM...\n",
      "/tmp/ipykernel_667385/401964209.py:66: SerializationWarning: Unable to decode time axis into full numpy.datetime64[ns] objects, continuing using cftime.datetime objects instead, reason: dates out of range. To silence this warning use a coarser resolution 'time_unit' or specify 'use_cftime=True'.\n",
      "  ds = xr.open_zarr(zarr_url, consolidated=True)\n",
      "2025-04-09 23:08:57,882 - INFO - Saved dataset to datasets/cmip6_tas_ssp245_CESM2-WACCM.nc\n",
      "2025-04-09 23:08:57,883 - INFO - Downloading historical tas data for MIROC6...\n",
      "2025-04-09 23:08:58,485 - INFO - Saved dataset to datasets/cmip6_tas_ssp585_CESM2-WACCM.nc\n",
      "2025-04-09 23:08:58,487 - INFO - Downloading historical pr data for MIROC6...\n",
      "2025-04-09 23:08:58,802 - INFO - Saved dataset to datasets/cmip6_pr_ssp245_CESM2-WACCM.nc\n",
      "2025-04-09 23:08:58,803 - INFO - Downloading ssp245 tas data for MIROC6...\n",
      "/exports/csce/datastore/geos/users/s1895689/basemap/lib/python3.12/site-packages/dask/array/core.py:138: SerializationWarning: Unable to decode time axis into full numpy.datetime64[ns] objects, continuing using cftime.datetime objects instead, reason: dates out of range. To silence this warning use a coarser resolution 'time_unit' or specify 'use_cftime=True'.\n",
      "  c = np.asarray(c)\n",
      "2025-04-09 23:09:04,281 - INFO - Saved dataset to datasets/cmip6_tas_historical_MIROC6.nc\n",
      "2025-04-09 23:09:04,282 - INFO - Downloading ssp245 pr data for MIROC6...\n",
      "2025-04-09 23:09:04,502 - INFO - Saved dataset to datasets/cmip6_tas_ssp245_MIROC6.nc\n",
      "2025-04-09 23:09:04,503 - INFO - Downloading ssp585 tas data for MIROC6...\n",
      "2025-04-09 23:09:05,050 - INFO - Saved dataset to datasets/cmip6_pr_historical_MIROC6.nc\n",
      "2025-04-09 23:09:05,051 - INFO - Downloading ssp585 pr data for MIROC6...\n",
      "2025-04-09 23:09:05,696 - INFO - Saved dataset to datasets/cmip6_pr_ssp585_CESM2-WACCM.nc\n",
      "2025-04-09 23:09:08,486 - INFO - Saved dataset to datasets/cmip6_tas_ssp585_MIROC6.nc\n",
      "2025-04-09 23:09:09,626 - INFO - Saved dataset to datasets/cmip6_pr_ssp245_MIROC6.nc\n",
      "2025-04-09 23:09:10,231 - INFO - Saved dataset to datasets/cmip6_pr_ssp585_MIROC6.nc\n",
      "2025-04-09 23:09:10,247 - INFO - All downloads complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Define constants\n",
    "CATALOG_URL = \"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\"\n",
    "OUTPUT_DIR = Path(\"datasets\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read the CMIP6 data catalog\n",
    "logging.info(\"Downloading CMIP6 catalog...\")\n",
    "df = pd.read_csv(CATALOG_URL)\n",
    "\n",
    "# Convert catalog to dictionary for faster lookups\n",
    "dataset_lookup = {\n",
    "    tuple(row[['source_id', 'experiment_id', 'variable_id', 'member_id', 'table_id']]): row['zstore']\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Define model configurations\n",
    "model_configs = {\n",
    "    \"UKESM1-0-LL\": \"r1i1p1f2\",\n",
    "    \"CESM2-WACCM\": \"r1i1p1f1\",\n",
    "    \"MIROC6\": \"r1i1p1f1\"\n",
    "}\n",
    "experiments = [\"historical\", \"ssp245\", \"ssp585\"]\n",
    "variables = [\"tas\", \"pr\"]\n",
    "table_id = \"Amon\"\n",
    "\n",
    "# Generate full list of datasets\n",
    "datasets = []\n",
    "for model, member in model_configs.items():\n",
    "    for exp in experiments:\n",
    "        for var in variables:\n",
    "            datasets.append({\n",
    "                \"source\": model,\n",
    "                \"experiment\": exp,\n",
    "                \"variable\": var,\n",
    "                \"member\": member,\n",
    "                \"table\": table_id\n",
    "            })\n",
    "\n",
    "def download_cmip6_data(dataset):\n",
    "    \"\"\"Download CMIP6 data and save as NetCDF.\"\"\"\n",
    "    try:\n",
    "        source, experiment, variable, member, table = dataset.values()\n",
    "        output_path = OUTPUT_DIR / f\"cmip6_{variable}_{experiment}_{source}.nc\"\n",
    "        \n",
    "        if output_path.exists():\n",
    "            logging.info(f\"File already exists, skipping: {output_path}\")\n",
    "            return\n",
    "\n",
    "        dataset_key = (source, experiment, variable, member, table)\n",
    "        zarr_url = dataset_lookup.get(dataset_key)\n",
    "\n",
    "        if not zarr_url:\n",
    "            logging.warning(f\"No data found for {dataset_key}\")\n",
    "            return\n",
    "\n",
    "        logging.info(f\"Downloading {experiment} {variable} data for {source}...\")\n",
    "        ds = xr.open_zarr(zarr_url, consolidated=True)\n",
    "        ds.to_netcdf(output_path)\n",
    "        logging.info(f\"Saved dataset to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading {dataset}: {e}\")\n",
    "\n",
    "# Parallel download\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(download_cmip6_data, datasets)\n",
    "\n",
    "logging.info(\"All downloads complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
