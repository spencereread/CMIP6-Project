{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045f153e-7743-42ed-a4c0-8fe05e5e697b",
   "metadata": {},
   "source": [
    "This notebook filters and selects the required CMIP6 datasets based on specified models, variables, scenarios, and locations. It then downloads the relevant data and saves it locally in .nc (NetCDF) format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1560d11f-1c4c-4327-a573-dc474cd2b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 17:58:39,315 - INFO - Downloading CMIP6 catalog...\n",
      "2025-04-04 17:59:38,993 - INFO - Downloading historical tas data for UKESM1-0-LL...\n",
      "2025-04-04 17:59:38,994 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp245_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:38,994 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp245_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:38,994 - INFO - Downloading historical pr data for UKESM1-0-LL...\n",
      "2025-04-04 17:59:38,998 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp585_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:38,999 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp585_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:39,000 - INFO - Downloading historical tas data for CESM2-WACCM...\n",
      "2025-04-04 17:59:39,000 - INFO - Downloading historical pr data for CESM2-WACCM...\n",
      "2025-04-04 17:59:44,065 - INFO - Saved dataset to datasets/cmip6_tas_historical_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:44,070 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp245_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:44,074 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp245_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:44,079 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp585_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:44,084 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp585_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:44,085 - INFO - Downloading historical tas data for MIROC6...\n",
      "2025-04-04 17:59:44,633 - INFO - Saved dataset to datasets/cmip6_pr_historical_UKESM1-0-LL.nc\n",
      "2025-04-04 17:59:44,635 - INFO - Downloading historical pr data for MIROC6...\n",
      "2025-04-04 17:59:45,396 - INFO - Saved dataset to datasets/cmip6_tas_historical_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:45,399 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp245_MIROC6.nc\n",
      "2025-04-04 17:59:45,400 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp245_MIROC6.nc\n",
      "2025-04-04 17:59:45,401 - INFO - File already exists, skipping: datasets/cmip6_tas_ssp585_MIROC6.nc\n",
      "2025-04-04 17:59:45,403 - INFO - File already exists, skipping: datasets/cmip6_pr_ssp585_MIROC6.nc\n",
      "2025-04-04 17:59:46,334 - INFO - Saved dataset to datasets/cmip6_pr_historical_CESM2-WACCM.nc\n",
      "2025-04-04 17:59:49,216 - INFO - Saved dataset to datasets/cmip6_tas_historical_MIROC6.nc\n",
      "2025-04-04 17:59:49,727 - INFO - Saved dataset to datasets/cmip6_pr_historical_MIROC6.nc\n",
      "2025-04-04 17:59:49,728 - INFO - All downloads complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Define constants\n",
    "CATALOG_URL = \"https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv\"\n",
    "OUTPUT_DIR = Path(\"datasets\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read the CMIP6 data catalog\n",
    "logging.info(\"Downloading CMIP6 catalog...\")\n",
    "df = pd.read_csv(CATALOG_URL)\n",
    "\n",
    "# Convert catalog to dictionary for faster lookups\n",
    "dataset_lookup = {\n",
    "    tuple(row[['source_id', 'experiment_id', 'variable_id', 'member_id', 'table_id']]): row['zstore']\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Define model configurations\n",
    "model_configs = {\n",
    "    \"UKESM1-0-LL\": \"r1i1p1f2\",\n",
    "    \"CESM2-WACCM\": \"r1i1p1f1\",\n",
    "    \"MIROC6\": \"r1i1p1f1\"\n",
    "}\n",
    "experiments = [\"historical\", \"ssp245\", \"ssp585\"]\n",
    "variables = [\"tas\", \"pr\"]\n",
    "table_id = \"Amon\"\n",
    "\n",
    "# Generate full list of datasets\n",
    "datasets = []\n",
    "for model, member in model_configs.items():\n",
    "    for exp in experiments:\n",
    "        for var in variables:\n",
    "            datasets.append({\n",
    "                \"source\": model,\n",
    "                \"experiment\": exp,\n",
    "                \"variable\": var,\n",
    "                \"member\": member,\n",
    "                \"table\": table_id\n",
    "            })\n",
    "\n",
    "def download_cmip6_data(dataset):\n",
    "    \"\"\"Download CMIP6 data and save as NetCDF.\"\"\"\n",
    "    try:\n",
    "        source, experiment, variable, member, table = dataset.values()\n",
    "        output_path = OUTPUT_DIR / f\"cmip6_{variable}_{experiment}_{source}.nc\"\n",
    "        \n",
    "        if output_path.exists():\n",
    "            logging.info(f\"File already exists, skipping: {output_path}\")\n",
    "            return\n",
    "\n",
    "        dataset_key = (source, experiment, variable, member, table)\n",
    "        zarr_url = dataset_lookup.get(dataset_key)\n",
    "\n",
    "        if not zarr_url:\n",
    "            logging.warning(f\"No data found for {dataset_key}\")\n",
    "            return\n",
    "\n",
    "        logging.info(f\"Downloading {experiment} {variable} data for {source}...\")\n",
    "        ds = xr.open_zarr(zarr_url, consolidated=True)\n",
    "        ds.to_netcdf(output_path)\n",
    "        logging.info(f\"Saved dataset to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading {dataset}: {e}\")\n",
    "\n",
    "# Parallel download\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(download_cmip6_data, datasets)\n",
    "\n",
    "logging.info(\"All downloads complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
