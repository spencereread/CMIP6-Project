{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f7c307-d3dd-4645-9c08-d689b8e528a2",
   "metadata": {},
   "source": [
    "This notebook analyses precipitation data to assess changes during typhoon season in Tokyo. It generates visualizations that illustrate projected changes in rainfall patterns under different climate scenarios for July, August, September and October, when typhoons are most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a98da57-2fec-4fd7-83b0-4d21c46f18a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 12:18:47,778 - INFO - Loading datasets...\n",
      "2025-04-24 12:18:49,152 - INFO - Converted precipitation from kg/m^2/s to mm/month\n",
      "2025-04-24 12:18:49,153 - INFO - Loaded historical data for model MIROC6\n",
      "2025-04-24 12:18:49,681 - INFO - Converted precipitation from kg/m^2/s to mm/month\n",
      "2025-04-24 12:18:49,682 - INFO - Loaded ssp245 data for model MIROC6\n",
      "2025-04-24 12:18:50,198 - INFO - Converted precipitation from kg/m^2/s to mm/month\n",
      "2025-04-24 12:18:50,199 - INFO - Loaded ssp585 data for model MIROC6\n",
      "2025-04-24 12:18:50,200 - INFO - Extracting Tokyo data...\n",
      "2025-04-24 12:18:50,202 - INFO - Extracted Tokyo data for historical\n",
      "2025-04-24 12:18:50,203 - INFO - Time range: 1850-01-16T12:00:00.000000000 to 2014-12-16T12:00:00.000000000\n",
      "2025-04-24 12:18:50,203 - INFO - Extracted Tokyo data for ssp245\n",
      "2025-04-24 12:18:50,204 - INFO - Time range: 2015-01-16T12:00:00.000000000 to 2100-12-16T12:00:00.000000000\n",
      "2025-04-24 12:18:50,205 - INFO - Extracted Tokyo data for ssp585\n",
      "2025-04-24 12:18:50,206 - INFO - Time range: 2015-01-16T12:00:00.000000000 to 2100-12-16T12:00:00.000000000\n",
      "2025-04-24 12:18:50,207 - INFO - Creating key metric comparisons...\n",
      "2025-04-24 12:18:50,347 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,348 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,349 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,387 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,388 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,389 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,923 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,924 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,925 - WARNING - posx and posy should be finite values\n",
      "2025-04-24 12:18:50,956 - INFO - Creating monthly intensity change visualizations...\n",
      "2025-04-24 12:18:56,036 - INFO - Analysis complete! Figures saved to: ./figures\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import calendar\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.cm as cm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def load_datasets(data_paths):\n",
    "    \"\"\"\n",
    "    Load CMIP6 datasets from given paths\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_paths : list\n",
    "        List of paths to NetCDF files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of loaded datasets\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    for path in data_paths:\n",
    "        try:\n",
    "            # Extract scenario from filename\n",
    "            path_obj = Path(path)\n",
    "            filename = path_obj.name\n",
    "            \n",
    "            # Parse scenario from filename (assuming format cmip6_pr_SCENARIO_MODEL.nc)\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                scenario = parts[2]  # Get the scenario part\n",
    "                model = parts[3].split('.')[0]  # Get model name without extension\n",
    "                \n",
    "                # Load dataset\n",
    "                ds = xr.open_dataset(path)\n",
    "                \n",
    "                # Check if precipitation variable exists\n",
    "                if 'pr' in ds:\n",
    "                    # Convert from kg/m^2/s to mm/month if needed\n",
    "                    if ds.pr.max() < 1:  # Likely in kg/m^2/s\n",
    "                        # First convert to datetime to determine days in each month\n",
    "                        time_data = pd.to_datetime(ds.time.values)\n",
    "                        days_in_month = np.array([calendar.monthrange(dt.year, dt.month)[1] \n",
    "                                                for dt in time_data])\n",
    "                        \n",
    "                        # Create a DataArray with the same time dimension as pr\n",
    "                        days_array = xr.DataArray(days_in_month, dims=['time'], coords={'time': ds.time})\n",
    "                        \n",
    "                        # Use xarray broadcasting to multiply correctly across dimensions\n",
    "                        ds['pr'] = ds.pr * 86400 * days_array\n",
    "                        logging.info(f\"Converted precipitation from kg/m^2/s to mm/month\")\n",
    "                    \n",
    "                    # Store in dictionary\n",
    "                    if scenario not in datasets:\n",
    "                        datasets[scenario] = {}\n",
    "                    \n",
    "                    datasets[scenario]['pr'] = ds.pr\n",
    "                    logging.info(f\"Loaded {scenario} data for model {model}\")\n",
    "                else:\n",
    "                    logging.warning(f\"No precipitation data found in {path}\")\n",
    "            else:\n",
    "                logging.warning(f\"Could not parse scenario from filename: {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading dataset {path}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "def extract_tokyo_data(datasets, tokyo_lat=35.6762, tokyo_lon=139.6503):\n",
    "    \"\"\"\n",
    "    Extract data for Tokyo from datasets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    datasets : dict\n",
    "        Dictionary of datasets by scenario\n",
    "    tokyo_lat : float\n",
    "        Latitude of Tokyo\n",
    "    tokyo_lon : float\n",
    "        Longitude of Tokyo\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of Tokyo data by scenario\n",
    "    \"\"\"\n",
    "    tokyo_data = {}\n",
    "    \n",
    "    for scenario, data in datasets.items():\n",
    "        if 'pr' in data:\n",
    "            # Find closest grid point to Tokyo\n",
    "            pr_data = data['pr']\n",
    "            \n",
    "            # Check if coordinates are 1D or 2D\n",
    "            if len(pr_data.lat.shape) == 1 and len(pr_data.lon.shape) == 1:\n",
    "                # For 1D coordinates\n",
    "                lat_idx = abs(pr_data.lat - tokyo_lat).argmin().item()\n",
    "                lon_idx = abs(pr_data.lon - tokyo_lon).argmin().item()\n",
    "                \n",
    "                # Extract data for Tokyo\n",
    "                tokyo_pr = pr_data.isel(lat=lat_idx, lon=lon_idx)\n",
    "            else:\n",
    "                # For 2D coordinates, find the index of minimum distance\n",
    "                lat_diff = abs(pr_data.lat - tokyo_lat)\n",
    "                lon_diff = abs(pr_data.lon - tokyo_lon)\n",
    "                total_diff = lat_diff + lon_diff\n",
    "                min_idx = total_diff.argmin()\n",
    "                \n",
    "                # Convert to 2D indices\n",
    "                lat_idx, lon_idx = np.unravel_index(min_idx, pr_data.lat.shape)\n",
    "                \n",
    "                # Extract data for Tokyo\n",
    "                tokyo_pr = pr_data.isel(lat=lat_idx, lon=lon_idx)\n",
    "            \n",
    "            # Store in dictionary\n",
    "            tokyo_data[scenario] = {'pr': tokyo_pr}\n",
    "            \n",
    "            logging.info(f\"Extracted Tokyo data for {scenario}\")\n",
    "            logging.info(f\"Time range: {tokyo_pr.time.min().values} to {tokyo_pr.time.max().values}\")\n",
    "    \n",
    "    return tokyo_data\n",
    "\n",
    "def analyze_typhoon_season(pr_data, time_periods=None):\n",
    "    \"\"\"\n",
    "    Analyze precipitation during typhoon season (July-October)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pr_data : xarray.DataArray\n",
    "        Precipitation data for Tokyo (mm/month)\n",
    "    time_periods : list of tuples, optional\n",
    "        List of (start_year, end_year) tuples for analysis periods\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of typhoon season precipitation metrics\n",
    "    \"\"\"\n",
    "    if time_periods is None:\n",
    "        # Default: split into historical and future periods\n",
    "        if pr_data.time.dt.year.min() < 2015:\n",
    "            # For historical data\n",
    "            time_periods = [(int(pr_data.time.dt.year.min().values), 2014)]\n",
    "        else:\n",
    "            # For future data\n",
    "            time_periods = [(2015, int(pr_data.time.dt.year.max().values))]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for start_year, end_year in time_periods:\n",
    "        period_label = f\"{start_year}-{end_year}\"\n",
    "        \n",
    "        # Check if there is data for this period\n",
    "        if start_year > pr_data.time.dt.year.max() or end_year < pr_data.time.dt.year.min():\n",
    "            logging.warning(f\"No data available for period {period_label}\")\n",
    "            continue\n",
    "        \n",
    "        period_data = pr_data.sel(time=slice(f\"{start_year}\", f\"{end_year}\"))\n",
    "        \n",
    "        if len(period_data) == 0:\n",
    "            logging.warning(f\"No data available for period {period_label}\")\n",
    "            continue\n",
    "            \n",
    "        # Create a pandas DataFrame\n",
    "        df = period_data.to_dataframe(name='pr')\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Add date components\n",
    "        df['year'] = df['time'].dt.year\n",
    "        df['month'] = df['time'].dt.month\n",
    "        df['day'] = df['time'].dt.day\n",
    "        \n",
    "        # Filter for typhoon season (July-October)\n",
    "        typhoon_season = df[(df['month'] >= 7) & (df['month'] <= 10)]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        season_mean = typhoon_season.groupby('year')['pr'].mean()\n",
    "        season_max = typhoon_season.groupby('year')['pr'].max()\n",
    "        season_sum = typhoon_season.groupby('year')['pr'].sum()\n",
    "        \n",
    "        # Count extreme precipitation months during typhoon season\n",
    "        # Define thresholds for different levels of extreme precipitation\n",
    "        # These are adjusted from daily to monthly values (approximately 30x the daily values)\n",
    "        extreme_thresholds = {\n",
    "            'moderate': 900,  # mm/month (was 30 mm/day)\n",
    "            'heavy': 1500,    # mm/month (was 50 mm/day) \n",
    "            'severe': 2400    # mm/month (was 80 mm/day)\n",
    "        }\n",
    "        \n",
    "        extreme_days = {\n",
    "            level: typhoon_season[typhoon_season['pr'] >= threshold].groupby('year').size()\n",
    "            for level, threshold in extreme_thresholds.items()\n",
    "        }\n",
    "        \n",
    "        # Calculate monthly distributions\n",
    "        monthly_data = {}\n",
    "        for month in range(7, 11):\n",
    "            month_data = typhoon_season[typhoon_season['month'] == month]\n",
    "            monthly_data[month] = {\n",
    "                'mean': month_data.groupby('year')['pr'].mean(),\n",
    "                'max': month_data.groupby('year')['pr'].max(),\n",
    "                'sum': month_data.groupby('year')['pr'].sum()\n",
    "            }\n",
    "        \n",
    "        # Calculate trends\n",
    "        years = season_mean.index.values\n",
    "        \n",
    "        # Mean precipitation trend\n",
    "        mean_slope, mean_intercept, mean_r, mean_p, mean_stderr = stats.linregress(years, season_mean)\n",
    "        \n",
    "        # Maximum precipitation trend\n",
    "        max_slope, max_intercept, max_r, max_p, max_stderr = stats.linregress(years, season_max)\n",
    "        \n",
    "        # Total precipitation trend\n",
    "        sum_slope, sum_intercept, sum_r, sum_p, sum_stderr = stats.linregress(years, season_sum)\n",
    "        \n",
    "        # Store results\n",
    "        results[period_label] = {\n",
    "            'season_mean': season_mean,\n",
    "            'season_max': season_max,\n",
    "            'season_sum': season_sum,\n",
    "            'extreme_days': extreme_days,\n",
    "            'monthly_data': monthly_data,\n",
    "            'raw_data': typhoon_season,\n",
    "            'mean_trend': {\n",
    "                'slope': mean_slope,\n",
    "                'intercept': mean_intercept,\n",
    "                'p_value': mean_p,\n",
    "                'r_value': mean_r\n",
    "            },\n",
    "            'max_trend': {\n",
    "                'slope': max_slope,\n",
    "                'intercept': max_intercept,\n",
    "                'p_value': max_p,\n",
    "                'r_value': max_r\n",
    "            },\n",
    "            'sum_trend': {\n",
    "                'slope': sum_slope,\n",
    "                'intercept': sum_intercept,\n",
    "                'p_value': sum_p,\n",
    "                'r_value': sum_r\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    return results\n",
    "\n",
    "def plot_scenario_comparison_key_metrics(tokyo_data, model_name, output_dir=\"./figures\"):\n",
    "    \"\"\"\n",
    "    Create comparison plots between historical and future scenarios for key metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tokyo_data : dict\n",
    "        Dictionary of Tokyo datasets by scenario\n",
    "    model_name : str\n",
    "        Name of the climate model\n",
    "    output_dir : str\n",
    "        Directory to save output figures\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Setup figure aesthetics\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_context(\"paper\", font_scale=1.4)\n",
    "    \n",
    "    # Extract data for each scenario\n",
    "    scenario_results = {}\n",
    "    \n",
    "    for scenario, data in tokyo_data.items():\n",
    "        if 'pr' not in data:\n",
    "            continue\n",
    "            \n",
    "        # Define time periods based on scenario\n",
    "        if 'historical' in scenario:\n",
    "            time_periods = [(int(data['pr'].time.dt.year.min().values), 2014)]\n",
    "        else:\n",
    "            time_periods = [(2015, int(data['pr'].time.dt.year.max().values))]\n",
    "        \n",
    "        # Analyze typhoon season\n",
    "        results = analyze_typhoon_season(data['pr'], time_periods)\n",
    "        \n",
    "        # Store results\n",
    "        scenario_results[scenario] = results\n",
    "    \n",
    "    # Create a figure for key metrics\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 16))\n",
    "    \n",
    "    # Colors for scenarios\n",
    "    colors = {\n",
    "        'historical': 'darkblue',\n",
    "        'ssp245': 'orange',\n",
    "        'ssp585': 'darkred'\n",
    "    }\n",
    "    \n",
    "    # Labels for scenarios\n",
    "    labels = {\n",
    "        'historical': 'Historical',\n",
    "        'ssp245': 'SSP2-4.5 (Moderate)',\n",
    "        'ssp585': 'SSP5-8.5 (High)'\n",
    "    }\n",
    "    \n",
    "    # 1. Extreme Precipitation Months\n",
    "    ax = axes[0]\n",
    "    \n",
    "    for scenario, results in scenario_results.items():\n",
    "        # Process only the first time period for each scenario\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        period = list(results.keys())[0]\n",
    "        period_results = results[period]\n",
    "        \n",
    "        # Calculate average number of extreme months per year\n",
    "        for threshold_name, threshold_data in period_results['extreme_days'].items():\n",
    "            if threshold_name == 'heavy':  # Focus on heavy precipitation (e1500mm/month)\n",
    "                avg_months = threshold_data.mean()\n",
    "                years = len(threshold_data)\n",
    "                \n",
    "                # Plot as a horizontal bar\n",
    "                ax.barh(\n",
    "                    labels.get(scenario, scenario),\n",
    "                    avg_months,\n",
    "                    color=colors.get(scenario, 'gray'),\n",
    "                    alpha=0.7,\n",
    "                    xerr=threshold_data.std(),\n",
    "                    capsize=5,\n",
    "                    height=0.6\n",
    "                )\n",
    "                \n",
    "                # Add the value at the end of each bar\n",
    "                ax.text(\n",
    "                    avg_months + 0.1,\n",
    "                    labels.get(scenario, scenario),\n",
    "                    f\"{avg_months:.2f} months/year\",\n",
    "                    va='center'\n",
    "                )\n",
    "    \n",
    "    ax.set_xlabel('Average Number of Heavy Precipitation Months (e1500mm) per Year')\n",
    "    ax.set_title('Heavy Precipitation Months During Typhoon Season (Jul-Oct)')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 2. Maximum Precipitation Intensity\n",
    "    ax = axes[1]\n",
    "    \n",
    "    for scenario, results in scenario_results.items():\n",
    "        # Process only the first time period for each scenario\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        period = list(results.keys())[0]\n",
    "        period_results = results[period]\n",
    "        \n",
    "        # Get maximum precipitation data and calculate statistics\n",
    "        max_precip = period_results['season_max']\n",
    "        avg_max = max_precip.mean()\n",
    "        \n",
    "        # Plot as a violin plot\n",
    "        parts = ax.violinplot(\n",
    "            max_precip.values,\n",
    "            positions=[list(labels.values()).index(labels.get(scenario, scenario))],\n",
    "            showmeans=False,\n",
    "            showmedians=True,\n",
    "            widths=0.8\n",
    "        )\n",
    "        \n",
    "        # Color the violin plots\n",
    "        for pc in parts['bodies']:\n",
    "            pc.set_facecolor(colors.get(scenario, 'gray'))\n",
    "            pc.set_alpha(0.7)\n",
    "        \n",
    "        # Add a marker for the mean\n",
    "        ax.scatter(\n",
    "            list(labels.values()).index(labels.get(scenario, scenario)),\n",
    "            avg_max,\n",
    "            color='black',\n",
    "            marker='*',\n",
    "            s=200,\n",
    "            zorder=3\n",
    "        )\n",
    "        \n",
    "        # Add text with the mean value\n",
    "        ax.text(\n",
    "            list(labels.values()).index(labels.get(scenario, scenario)),\n",
    "            avg_max+12,\n",
    "            f\"Mean: {avg_max:.1f} mm\",\n",
    "            ha='center',\n",
    "            fontsize=10\n",
    "        )\n",
    "    \n",
    "    ax.set_ylabel('Maximum Monthly Precipitation (mm)')\n",
    "    ax.set_title('Maximum Monthly Precipitation During Typhoon Season (Jul-Oct)')\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels.values())\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a main title\n",
    "    plt.suptitle(\n",
    "        f'Typhoon Season Intensity Comparison - {model_name} Model',\n",
    "        fontsize=16\n",
    "    )\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(f\"{output_dir}/{model_name}_key_metrics_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_monthly_intensity_changes(tokyo_data, model_name, output_dir=\"./figures\"):\n",
    "    \"\"\"\n",
    "    Create a visualization showing changes in monthly precipitation intensity\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tokyo_data : dict\n",
    "        Dictionary of Tokyo datasets by scenario\n",
    "    model_name : str\n",
    "        Name of the climate model\n",
    "    output_dir : str\n",
    "        Directory to save output figures\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Setup figure aesthetics\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_context(\"paper\", font_scale=1.4)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Month names\n",
    "    month_names = {7: 'July', 8: 'August', 9: 'September', 10: 'October'}\n",
    "    \n",
    "    # Extract data for historical scenario\n",
    "    historical_data = None\n",
    "    future_data = {'ssp245': None, 'ssp585': None}\n",
    "    \n",
    "    for scenario, data in tokyo_data.items():\n",
    "        if 'pr' not in data:\n",
    "            continue\n",
    "            \n",
    "        # Convert to dataframe\n",
    "        df = data['pr'].to_dataframe(name='pr').reset_index()\n",
    "        df['year'] = df['time'].dt.year\n",
    "        df['month'] = df['time'].dt.month\n",
    "        \n",
    "        # Filter for typhoon season\n",
    "        typhoon_df = df[(df['month'] >= 7) & (df['month'] <= 10)]\n",
    "        \n",
    "        if 'historical' in scenario:\n",
    "            historical_data = typhoon_df\n",
    "        elif 'ssp245' in scenario:\n",
    "            future_data['ssp245'] = typhoon_df\n",
    "        elif 'ssp585' in scenario:\n",
    "            future_data['ssp585'] = typhoon_df\n",
    "    \n",
    "    # If we don't have historical data, we can't proceed\n",
    "    if historical_data is None:\n",
    "        logging.warning(\"No historical data available for comparison\")\n",
    "        return None\n",
    "    \n",
    "    # Process data for each month\n",
    "    for i, month in enumerate(range(7, 11)):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Extract historical data for this month\n",
    "        hist_month = historical_data[historical_data['month'] == month]\n",
    "        hist_values = hist_month['pr'].values\n",
    "        \n",
    "        # Create a dictionary to store future scenario data\n",
    "        future_values = {}\n",
    "        \n",
    "        # Process each future scenario\n",
    "        for scenario, future_df in future_data.items():\n",
    "            if future_df is not None:\n",
    "                # Extract data for this month\n",
    "                future_month = future_df[future_df['month'] == month]\n",
    "                future_values[scenario] = future_month['pr'].values\n",
    "        \n",
    "        # Create the plot\n",
    "        # Historical data\n",
    "        sns.kdeplot(\n",
    "            hist_values,\n",
    "            ax=ax,\n",
    "            color='darkblue',\n",
    "            label='Historical',\n",
    "            fill=True,\n",
    "            alpha=0.3\n",
    "        )\n",
    "        \n",
    "        # Future scenarios\n",
    "        for scenario, values in future_values.items():\n",
    "            if scenario == 'ssp245':\n",
    "                color = 'orange'\n",
    "                label = 'SSP2-4.5 (Moderate)'\n",
    "            else:\n",
    "                color = 'darkred'\n",
    "                label = 'SSP5-8.5 (High)'\n",
    "                \n",
    "            sns.kdeplot(\n",
    "                values,\n",
    "                ax=ax,\n",
    "                color=color,\n",
    "                label=label,\n",
    "                fill=True,\n",
    "                alpha=0.3\n",
    "            )\n",
    "        \n",
    "        # Add median lines\n",
    "        ax.axvline(\n",
    "            np.median(hist_values),\n",
    "            color='darkblue',\n",
    "            linestyle='--',\n",
    "            label='Historical Median'\n",
    "        )\n",
    "        \n",
    "        for scenario, values in future_values.items():\n",
    "            if scenario == 'ssp245':\n",
    "                color = 'orange'\n",
    "                label = 'SSP2-4.5 Median'\n",
    "            else:\n",
    "                color = 'darkred'\n",
    "                label = 'SSP5-8.5 Median'\n",
    "                \n",
    "            ax.axvline(\n",
    "                np.median(values),\n",
    "                color=color,\n",
    "                linestyle='--',\n",
    "                label=label\n",
    "            )\n",
    "        \n",
    "        # Calculate percent changes for annotation\n",
    "        hist_median = np.median(hist_values)\n",
    "        changes_text = []\n",
    "        \n",
    "        for scenario, values in future_values.items():\n",
    "            future_median = np.median(values)\n",
    "            percent_change = ((future_median - hist_median) / hist_median) * 100\n",
    "            \n",
    "            if scenario == 'ssp245':\n",
    "                scenario_label = 'SSP2-4.5'\n",
    "            else:\n",
    "                scenario_label = 'SSP5-8.5'\n",
    "                \n",
    "            changes_text.append(f\"{scenario_label}: {percent_change:.1f}% change\")\n",
    "        \n",
    "        # Add the changes as text annotation\n",
    "        ax.text(\n",
    "            0.05, 0.95,\n",
    "            '\\n'.join(changes_text),\n",
    "            transform=ax.transAxes,\n",
    "            va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "        )\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(f'{month_names[month]}')\n",
    "        ax.set_xlabel('Monthly Precipitation (mm)')\n",
    "        \n",
    "        if i == 0 or i == 2:\n",
    "            ax.set_ylabel('Density')\n",
    "        \n",
    "        # Add legend only to the first plot\n",
    "        if i == 0:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "        else:\n",
    "            legend = ax.get_legend()\n",
    "            if legend is not None:  # Only remove if legend exists\n",
    "                legend.remove()\n",
    "    \n",
    "    # Add a main title\n",
    "    plt.suptitle(\n",
    "        f'Changes in Precipitation Distribution During Typhoon Season Months\\n{model_name} Model',\n",
    "        fontsize=16\n",
    "    )\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(f\"{output_dir}/{model_name}_monthly_intensity_changes.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the analysis\"\"\"\n",
    "    # Dataset paths\n",
    "    data_paths = [\n",
    "        \"datasets/cmip6_pr_historical_MIROC6.nc\",\n",
    "        \"datasets/cmip6_pr_ssp245_MIROC6.nc\",\n",
    "        \"datasets/cmip6_pr_ssp585_MIROC6.nc\"\n",
    "    ]\n",
    "    \n",
    "    # Set model name\n",
    "    model_name = \"MIROC6\"\n",
    "    \n",
    "    # Load datasets\n",
    "    logging.info(\"Loading datasets...\")\n",
    "    datasets = load_datasets(data_paths)\n",
    "    \n",
    "    # Extract Tokyo data\n",
    "    logging.info(\"Extracting Tokyo data...\")\n",
    "    tokyo_data = extract_tokyo_data(datasets)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"./figures\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create key visualizations\n",
    "    logging.info(\"Creating key metric comparisons...\")\n",
    "    fig1 = plot_scenario_comparison_key_metrics(tokyo_data, model_name, output_dir)\n",
    "    \n",
    "    logging.info(\"Creating monthly intensity change visualizations...\")\n",
    "    fig2 = plot_monthly_intensity_changes(tokyo_data, model_name, output_dir)\n",
    "    \n",
    "    logging.info(\"Analysis complete! Figures saved to: \" + output_dir)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cdab0-72af-4744-b633-e5805aa2155b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
